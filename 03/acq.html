
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>Data acquisition &#8212; Open and reproducible neuroimaging: from study inception to publication</title>
    
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">
<link href="../_static/styles/pydata-sphinx-theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" href="../_static/styles/sphinx-book-theme.css?digest=5115cc725059bd94278eecd172e13a965bf8f5a9" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/custom.css" />
    <link rel="stylesheet" type="text/css" href="../_static/custom.css" />
    <link rel="stylesheet" type="text/css" href="../_static/custom.css" />
    <link rel="stylesheet" type="text/css" href="../_static/design-style.b7bb847fb20b106c3d81b95245e65545.min.css" />
    
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf">

    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script src="../_static/scripts/sphinx-book-theme.js?digest=9c920249402e914e316237a7dbc6769907cce411"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Research data management" href="../04/data.html" />
    <link rel="prev" title="Study inception, planning, and ethics" href="../02/ipe.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="60">
<!-- Checkboxes to toggle the left sidebar -->
<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation" aria-label="Toggle navigation sidebar">
<label class="overlay overlay-navbar" for="__navigation">
    <div class="visually-hidden">Toggle navigation sidebar</div>
</label>
<!-- Checkboxes to toggle the in-page toc -->
<input type="checkbox" class="sidebar-toggle" name="__page-toc" id="__page-toc" aria-label="Toggle in-page Table of Contents">
<label class="overlay overlay-pagetoc" for="__page-toc">
    <div class="visually-hidden">Toggle in-page Table of Contents</div>
</label>
<!-- Headers at the top -->
<div class="announcement header-item noprint">This work is currently under review.</div>
<div class="header header-item noprint"></div>

    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<!-- Sidebar -->
<div class="bd-sidebar noprint" id="site-navigation">
    <div class="bd-sidebar__content">
        <div class="bd-sidebar__top"><div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="../_static/icon.png" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">Open and reproducible neuroimaging: from study inception to publication</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../index.html">
                    Abstract
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Overview
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../01/introduction.html">
   Introduction
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Design
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../02/ipe.html">
   Study inception, planning, and ethics
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Acquisition
 </span>
</p>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   Data acquisition
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Data
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../04/data.html">
   Research data management
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Processing
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../05/proc.html">
   Data processing and analysis
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Sharing
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../06/dist.html">
   Research disemmination
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Conclusion
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../07/conclusion.html">
   Conclusions
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Contributions
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../08/contributions.html">
   Contributions
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Resources
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../09/table.html">
   Resources
  </a>
 </li>
</ul>

    </div>
</nav></div>
        <div class="bd-sidebar__bottom">
             <!-- To handle the deprecated key -->
            
            <div class="navbar_extra_footer">
            Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
            </div>
            
        </div>
    </div>
    <div id="rtd-footer-container"></div>
</div>


          


          
<!-- A tiny helper pixel to detect if we've scrolled -->
<div class="sbt-scroll-pixel-helper"></div>
<!-- Main content -->
<div class="col py-0 content-container">
    
    <div class="header-article row sticky-top noprint">
        



<div class="col py-1 d-flex header-article-main">
    <div class="header-article__left">
        
        <label for="__navigation"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="right"
title="Toggle navigation"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-bars"></i>
  </span>

</label>

        
    </div>
    <div class="header-article__right">
<button onclick="toggleFullScreen()"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="bottom"
title="Fullscreen mode"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>

<div class="menu-dropdown menu-dropdown-download-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Download this page">
      <i class="fas fa-download"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="../_sources/03/acq.md"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Download source file"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="headerbtn__text-container">.md</span>
</a>

      </li>
      
      <li>
        
<button onclick="printPdf(this)"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="left"
title="Print to PDF"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="headerbtn__text-container">.pdf</span>
</button>

      </li>
      
    </ul>
  </div>
</div>

    </div>
</div>

<!-- Table of contents -->
<div class="col-md-3 bd-toc show noprint">
</div>
    </div>
    <div class="article row">
        <div class="col pl-md-3 pl-lg-5 content-container">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>Data acquisition</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                    </div>
                </div>
            </div>
            <main id="main-content" role="main">
                
              <div>
                
  <section class="tex2jax_ignore mathjax_ignore" id="data-acquisition">
<h1>Data acquisition<a class="headerlink" href="#data-acquisition" title="Permalink to this headline">#</a></h1>
<div class="admonition-issue admonition">
<p class="admonition-title">Issue</p>
<p>Data acquisition is largely carried out with vendored systems. Manufacturers typically keep their software and hardware closed or semi-open at most. As a result, researchers often receive highly processed (e.g., reconstructed) data as ‘raw’ data from the devices. The lack of transparency in the acquisition details and downstream proprietary processing prevents end-to-end reproducible neuroimaging workflows. Reproducibility is endangered, for instance, by heterogeneity in data formats, definition of critical experimental parameters, and technological differences that are translated into the data as spurious, non-biological differences between acquisition devices.</p>
</div>
<div class="admonition-what-do-we-provide admonition">
<p class="admonition-title">What do we provide</p>
<p>These shortcomings of mostly closed solutions have triggered a growing interest in open-source acquisition hardware and software <span id="id1">[<a class="reference internal" href="#id281" title="Lukas Winter, H Haopeng, Antonia Barghoorn, Werner Hoffmann, Stefan Hetzer, Simone Winkler, and Others. Open source imaging initiative. Proc. of. the International Society for Magnetic Resonance in Medicine (ISMRM), 2016.">Winter <em>et al.</em>, 2016</a>]</span>. <strong>Here, we provide a brief review of these developments and accompanying solutions aimed at fostering open and collaborative acquisition method development across imaging modalities.</strong></p>
</div>
<figure class="align-default" id="fig2">
<img alt="../_images/fig2.png" src="../_images/fig2.png" />
<figcaption>
<p><span class="caption-number">Fig. 2 </span><span class="caption-text">Data acquisition <a class="footnote-reference brackets" href="#footnote2" id="id2">1</a>.</span><a class="headerlink" href="#fig2" title="Permalink to this image">#</a></p>
</figcaption>
</figure>
<details class="sd-sphinx-override sd-dropdown sd-card sd-mb-3 sd-fade-in">
<summary class="sd-summary-title sd-card-header bg-ch3 font-weight-bold">
<span class="fa fa-brain"></span> 3.1 Brain data acquisition<div class="sd-summary-down docutils">
<svg version="1.1" width="1.5em" height="1.5em" class="sd-octicon sd-octicon-chevron-down" viewBox="0 0 24 24" aria-hidden="true"><path fill-rule="evenodd" d="M5.22 8.72a.75.75 0 000 1.06l6.25 6.25a.75.75 0 001.06 0l6.25-6.25a.75.75 0 00-1.06-1.06L12 14.44 6.28 8.72a.75.75 0 00-1.06 0z"></path></svg></div>
<div class="sd-summary-up docutils">
<svg version="1.1" width="1.5em" height="1.5em" class="sd-octicon sd-octicon-chevron-up" viewBox="0 0 24 24" aria-hidden="true"><path fill-rule="evenodd" d="M18.78 15.28a.75.75 0 000-1.06l-6.25-6.25a.75.75 0 00-1.06 0l-6.25 6.25a.75.75 0 101.06 1.06L12 9.56l5.72 5.72a.75.75 0 001.06 0z"></path></svg></div>
</summary><div class="sd-summary-content sd-card-body docutils">
<p class="sd-card-text" id="s31">A common approach advocated by MRI researchers is establishing consensus protocols to standardize data acquisition. One of the flagship applications of this strategy is the Human Connectome Project (HCP) protocol, which achieved this within the confines of a single vendor <span id="id3">[<a class="reference internal" href="#id62" title="Stephen M Smith, Christian F Beckmann, Jesper Andersson, Edward J Auerbach, Janine Bijsterbosch, Gwenaëlle Douaud, Eugene Duff, David A Feinberg, Ludovica Griffanti, Michael P Harms, Michael Kelly, Timothy Laumann, Karla L Miller, Steen Moeller, Steve Petersen, Jonathan Power, Gholamreza Salimi-Khorshidi, Abraham Z Snyder, An T Vu, Mark W Woolrich, Junqian Xu, Essa Yacoub, Kamil Uğurbil, David C Van Essen, Matthew F Glasser, and WU-Minn HCP Consortium. Resting-state fMRI in the human connectome project. Neuroimage, 80:144–168, October 2013.">Smith <em>et al.</em>, 2013</a>]</span>. The HCP acquisition sequences and reconstruction software are compiled for different MRI scanner versions of a single vendor, openly distributed and maintained for fMRI applications <span id="id4">[<a class="reference internal" href="#id90" title="Kamil Uğurbil, Junqian Xu, Edward J Auerbach, Steen Moeller, An T Vu, Julio M Duarte-Carvajalino, Christophe Lenglet, Xiaoping Wu, Sebastian Schmitter, Pierre Francois Van de Moortele, John Strupp, Guillermo Sapiro, Federico De Martino, Dingxin Wang, Noam Harel, Michael Garwood, Liyong Chen, David A Feinberg, Stephen M Smith, Karla L Miller, Stamatios N Sotiropoulos, Saad Jbabdi, Jesper L R Andersson, Timothy E J Behrens, Matthew F Glasser, David C Van Essen, Essa Yacoub, and WU-Minn HCP Consortium. Pushing spatial and temporal resolution for functional and diffusion MRI in the human connectome project. Neuroimage, 80:80–104, October 2013.">Uğurbil <em>et al.</em>, 2013</a>]</span>. However, it is generally difficult to achieve good inter vendor agreement using off the shelf software even for widely used protocols, such as apparent diffusion coefficient and longitudinal relaxation time <span id="id5">[<a class="reference internal" href="#id198" title="Yoojin Lee, Martina F Callaghan, Julio Acosta-Cabronero, Antoine Lutti, and Zoltan Nagy. Establishing intra- and inter-vendor reproducibility of T relaxation time measurements with 3T MRI. Magnetic Resonance in Medicine, 81(1):454–465, January 2019.">Lee <em>et al.</em>, 2019</a>, <a class="reference internal" href="#id251" title="Makoto Sasaki, Kei Yamada, Yoshiyuki Watanabe, Mieko Matsui, Masahiro Ida, Shunrou Fujiwara, Eri Shibata, and Acute Stroke Imaging Standardization Group-Japan (ASIST-Japan) Investigators. Variability in absolute apparent diffusion coefficient values across different platforms may be substantial: a multivendor, multi-institutional comparison study. Radiology, 249(2):624–630, November 2008.">Sasaki <em>et al.</em>, 2008</a>]</span>. In addition, not all software options are available from all vendors (for example, compressed sensing <span id="id6">[<a class="reference internal" href="#id50" title="M Lustig, D L Donoho, J M Santos, and J M Pauly. Compressed sensing MRI. IEEE Signal Processing Magazine, 25(2):72–82, March 2008.">Lustig <em>et al.</em>, 2008</a>]</span> and frequency-domain based parallel imaging methods <span id="id7">[<a class="reference internal" href="#id131" title="Felix A Breuer, Martin Blaimer, Robin M Heidemann, Matthias F Mueller, Mark A Griswold, and Peter M Jakob. Controlled aliasing in parallel imaging results in higher acceleration (CAIPIRINHA) for multi-slice imaging. Magnetic Resonance in Medicine, 53(3):684–691, March 2005.">Breuer <em>et al.</em>, 2005</a>, <a class="reference internal" href="#id125" title="Mark A Griswold, Peter M Jakob, Robin M Heidemann, Mathias Nittka, Vladimir Jellus, Jianmin Wang, Berthold Kiefer, and Axel Haase. Generalized autocalibrating partially parallel acquisitions (GRAPPA). Magnetic Resonance in Medicine, 47(6):1202–1210, 2002.">Griswold <em>et al.</em>, 2002</a>]</span>). Moreover, even seemingly simple image enhancement protocols, such as image inhomogeneity corrections, are often scarcely documented and validated but can affect inferences drawn from an experiment (<span id="id8">[<a class="reference internal" href="#id189" title="Tina Schmitt and Jochem W Rieger. Recommendations of choice of head coil and prescan normalize filter depend on region of interest and task. Frontiers in Neuroscience, 2021.">Schmitt and Rieger, 2021</a>]</span>; e.g., <span id="id9">[<a class="reference internal" href="#id241" title="V Jellús and S A R Kannengiesser. Adaptive coil combination using a body coil scan as phase reference. Joint Annual Meeting ISMRM-ESMRMB, pages 4406, 2014.">Jellús and Kannengiesser, 2014</a>]</span>). Users typically have access to key parameters of pulse sequences, which are at the center of data acquisition. The exact pulse sequence descriptions are vendor-specific and may even change between software upgrades of a single vendor. This makes it difficult to evaluate multi-center validity of new acquisition methods or to acquire longitudinal data with confidence.</p>
<p class="sd-card-text">Fortunately, in the last decade, several vendor-neutral data acquisition pulse sequences and reconstruction frameworks have been developed to mitigate this problem: Pulseq <span id="id10">[<a class="reference internal" href="#id73" title="Kelvin J Layton, Stefan Kroboth, Feng Jia, Sebastian Littin, Huijun Yu, Jochen Leupold, Jon-Fredrik Nielsen, Tony Stöcker, and Maxim Zaitsev. Pulseq: a rapid and hardware-independent pulse sequence prototyping framework. Magnetic Resonance in Medicine, 77(4):1544–1552, April 2017.">Layton <em>et al.</em>, 2017</a>]</span>, PyPulseq <span id="id11">[<a class="reference internal" href="#id85" title="Keerthi Ravi, Sairam Geethanath, and John Vaughan. PyPulseq: a python package for MRI pulse sequence design. Journal of Open Source Software, 4(42):1725, October 2019.">Ravi <em>et al.</em>, 2019</a>]</span>, GammaStar <span id="id12">[<a class="reference internal" href="#id70" title="Cristoffer Cordes, Simon Konstandin, David Porter, and Matthias Günther. Portable and platform-independent MR pulse sequence programs. Magnetic Resonance in Medicine, 83(4):1277–1290, April 2020.">Cordes <em>et al.</em>, 2020</a>]</span>, TOPPE <span id="id13">[<a class="reference internal" href="#id209" title="Jon-Fredrik Nielsen and Douglas C Noll. TOPPE: a framework for rapid prototyping of MR pulse sequences. Magnetic Resonance in Medicine, 79(6):3128–3134, June 2018.">Nielsen and Noll, 2018</a>]</span>, ODIN <span id="id14">[<a class="reference internal" href="#id128" title="Thies H Jochimsen and Michael von Mengershausen. ODIN: object-oriented development interface for NMR. Journal of Magnetic Resonance, 170(1):67–78, 2004.">Jochimsen and von Mengershausen, 2004</a>]</span>, and SequenceTree <span id="id15">[<a class="reference internal" href="#id121" title="Jeremy F Magland, Cheng Li, Michael C Langham, and Felix W Wehrli. Pulse sequence programming in a dynamic visual environment: SequenceTree. Magnetic Resonance in Medicine, 75(1):257–265, January 2016.">Magland <em>et al.</em>, 2016</a>]</span> (see the <a class="reference internal" href="../09/table.html"><span class="doc std std-doc">resources table</span></a>). Although these tools vary in vendor compatibility and the flexibility of their acquisition runtime, they enable vendor-neutral deployment of pulse sequences with transparent access to all the details needed. Nevertheless, vendor-neutral raw data (k-space, i.e. the 2D or 3D Fourier space representation of the image) collection is half the battle.</p>
<p class="sd-card-text">To complete the puzzle of MR image acquisition, interoperable and open-source reconstruction frameworks are essential. Thanks to ISMRM-RD <span id="id16">[<a class="reference internal" href="#id89" title="Souheil J Inati, Joseph D Naegele, Nicholas R Zwart, Vinai Roopchansingh, Martin J Lizak, David C Hansen, Chia-Ying Liu, David Atkinson, Peter Kellman, Sebastian Kozerke, Hui Xue, Adrienne E Campbell-Washburn, Thomas S Sørensen, and Michael S Hansen. ISMRM raw data format: a proposed standard for MRI raw datasets. Magnetic Resonance in Medicine, 77(1):411–421, January 2017.">Inati <em>et al.</em>, 2017</a>]</span>, a k-space data standard, community-developed reconstruction tools can have a unified way to run advanced reconstruction algorithms against undersampled raw data <span id="id17">[<a class="reference internal" href="#id178" title="Oliver Maier, Steven Hubert Baete, Alexander Fyrdahl, Kerstin Hammernik, Seb Harrevelt, Lars Kasper, Agah Karakuzu, Michael Loecher, Franz Patzig, Ye Tian, Ke Wang, Daniel Gallichan, Martin Uecker, and Florian Knoll. CG-SENSE revisited: results from the first ISMRM reproducibility challenge. Magnetic Resonance in Medicine, 85(4):1821–1839, April 2021.">Maier <em>et al.</em>, 2021</a>]</span>. Some of these tools include Gadgetron <span id="id18">[<a class="reference internal" href="#id115" title="Michael Schacht Hansen and Thomas Sangild Sørensen. Gadgetron: an open source framework for medical image reconstruction. Magnetic Resonance in Medicine, 69(6):1768–1776, June 2013.">Hansen and Sørensen, 2013</a>]</span>, BART <span id="id19">[<a class="reference internal" href="#id52" title="Martin Uecker, Frank Ong, Jonathan I Tamir, Dara Bahri, Patrick Virtue, Joseph Y Cheng, Tao Zhang, and Michael Lustig. Berkeley advanced reconstruction toolbox (BART). Proc. of. the International Society for Magnetic Resonance in Medicine (ISMRM), October 2015.">Uecker <em>et al.</em>, 2015</a>]</span>, MRIReco.Jl <span id="id20">[<a class="reference internal" href="#id266" title="Tobias Knopp and Mirco Grosser. MRIReco.jl: an MRI reconstruction framework written in julia. Magnetic Resonance in Medicine, 86(3):1633–1646, September 2021.">Knopp and Grosser, 2021</a>]</span> (see the <a class="reference internal" href="../09/table.html"><span class="doc std std-doc">resources table</span></a> for further tools and details). By streamlining these acquisition and reconstruction tools using data standards at multiple levels <span id="id21">[<a class="reference internal" href="#id89" title="Souheil J Inati, Joseph D Naegele, Nicholas R Zwart, Vinai Roopchansingh, Martin J Lizak, David C Hansen, Chia-Ying Liu, David Atkinson, Peter Kellman, Sebastian Kozerke, Hui Xue, Adrienne E Campbell-Washburn, Thomas S Sørensen, and Michael S Hansen. ISMRM raw data format: a proposed standard for MRI raw datasets. Magnetic Resonance in Medicine, 77(1):411–421, January 2017.">Inati <em>et al.</em>, 2017</a>, <a class="reference internal" href="#id204" title="Agah Karakuzu, Stefan Appelhoff, Tibor Auer, Mathieu Boudreau, Franklin Feingold, Ali R Khan, Alberto Lazari, Christopher Markiewicz, Martjin j Mulder, Christophe Phillips, Taylor Salo, Nikola Stikov, Kirstie Whitaker, and Gilles Hollander. qMRI-BIDS: an extension to the brain imaging data structure for quantitative magnetic resonance imaging data. medRxiv, pages 2021.10.22.21265382, October 2021.">Karakuzu <em>et al.</em>, 2021</a>]</span> on a data-driven and container-mediated workflow engine <span id="id22">[<a class="reference internal" href="#id271" title="Paolo Di Tommaso, Maria Chatzou, Evan W Floden, Pablo Prieto Barja, Emilio Palumbo, and Cedric Notredame. Nextflow enables reproducible computational workflows. Nature Biotechnology, 35(4):316–319, April 2017.">Di Tommaso <em>et al.</em>, 2017</a>]</span>, end-to-end reproducible MRI workflows can be developed. A recent study has shown that this approach can significantly reduce inter-vendor variability of quantitative MRI measurements <span id="id23">[<a class="reference internal" href="#id38" title="Agah Karakuzu, Labonny Biswas, Julien Cohen‐Adad, and Nikola Stikov. Vendor‐neutral sequences and fully transparent workflows improve inter‐vendor reproducibility of quantitative mri. Magnetic Resonance in Medicine, 88(3):1212–1228, 2022.">Karakuzu <em>et al.</em>, 2022</a>, <a class="reference internal" href="#id93" title="Agah Karakuzu, Mathieu Boudreau, Tanguy Duval, Tommy Boshkovski, Ilana Leppert, Jean-François Cabana, Ian Gagnon, Pascale Beliveau, G Pike, Julien Cohen-Adad, and Nikola Stikov. qMRLab: quantitative MRI analysis, under one umbrella. Journal of Open Source Software, 5(53):2343, September 2020.">Karakuzu <em>et al.</em>, 2020</a>]</span>. Given the growing open-source MRI acquisition ecosystem, a variety of end-to-end workflows are possible. Therefore, community-driven validation frameworks have a key importance for interoperable solutions <span id="id24">[<a class="reference internal" href="#id246" title="Gehua Tong, Andreia S Gaspar, Enlin Qian, Keerthi Sravan Ravi, John Thomas Vaughan, Jr, Rita G Nunes, and Sairam Geethanath. A framework for validating open-source pulse sequences. Magnetic Resonance Imaging, 87:7–18, November 2021.">Tong <em>et al.</em>, 2021</a>]</span>. Facilitated by these standards, effective and open communication methods development sets the future direction for reproducible MRI research <span id="id25">[<a class="reference internal" href="#id232" title="Nikola Stikov, Joshua D Trzasko, and Matt A Bernstein. Reproducibility and the future of MRI research. Magnetic Resonance in Medicine, 82(6):1981–1983, December 2019.">Stikov <em>et al.</em>, 2019</a>]</span>.</p>
<p class="sd-card-text">In PET, the variety between different scanners is even larger than in MRI. An overview over different scanner types based on their usage for a specific radiotracer targeting the serotonin transporter, namely [11C]DASB, is given in <span id="id26">[<a class="reference internal" href="#id43" title="Martin Nørgaard, Melanie Ganz, Claus Svarer, Ling Feng, Masanori Ichise, Rupert Lanzenberger, Mark Lubberink, Ramin V Parsey, Marios Politis, Eugenii A Rabiner, Mark Slifstein, Vesna Sossi, Tetsuya Suhara, Peter S Talbot, Federico Turkheimer, Stephen C Strother, and Gitte M Knudsen. Cerebral serotonin transporter measurements with [11C]DASB: a review on acquisition and preprocessing across 21 PET centres. Journal of Cerebral Blood Flow &amp; Metabolism, 39(2):210–222, 2019.">Nørgaard <em>et al.</em>, 2019</a>]</span>. Different PET scanners export images in slightly different data formats with little overlap in the Digital Imaging and Communications in Medicine (DICOM) PET specific tags. As with MRI, reconstruction is vendor/machine specific but open source solutions to image reconstruction are being developed, for instance the OMEGA toolbox <span id="id27">[<a class="reference internal" href="#id80" title="V-V Wettenhovi, M Vauhkonen, and V Kolehmainen. OMEGA: open-source emission tomography software. Physics in Medicine and Biology, 2021.">Wettenhovi <em>et al.</em>, 2021</a>]</span>. Data acquisition for PET is further complicated by the use of different PET tracers, injection methods, scan duration and scan framing or injected radioactivity dose.</p>
<p class="sd-card-text">In MEG and EEG, the problem of standardized data acquisition starts even earlier: unlike the common DICOM data format used across vendors in MRI or PET, MEG and EEG manufacturers do not use a common data format, and format specifications are rarely made public. More importantly, equipment implementation significantly differs between vendors, for example with respect to MEG sensor types,(software noise suppression techniques, and EEG amplifiers and electrodes. There have been some efforts on developing open versions of some proprietary tools, for example, the Maxwell filtering for signal space separation by the MNE-python team <span id="id28">[<a class="reference internal" href="../05/proc.html#id289" title="Alexandre Gramfort, Martin Luessi, Eric Larson, Denis A Engemann, Daniel Strohmeier, Christian Brodbeck, Lauri Parkkonen, and Matti S Hämäläinen. MNE software for processing MEG and EEG data. Neuroimage, 86:446–460, February 2014.">Gramfort <em>et al.</em>, 2014</a>]</span>. Additionally, initiatives, such as the OpenBCI, offer open EEG hardware and tools for biosensing and brain computer interfacing through continuous community driven development. As we have mentioned, very little is known on how the variability of data acquisition parameters affect downstream comparability of results. The EEGManyLabs project <span id="id29">[<a class="reference internal" href="../06/dist.html#id291" title="Yuri G Pavlov, Nika Adamian, Stefan Appelhoff, Mahnaz Arvaneh, Christopher S Y Benwell, Christian Beste, Amy R Bland, Daniel E Bradford, Florian Bublatzky, Niko A Busch, Peter E Clayson, Damian Cruse, Artur Czeszumski, Anna Dreber, Guillaume Dumas, Benedikt Ehinger, Giorgio Ganis, Xun He, José A Hinojosa, Christoph Huber-Huber, Michael Inzlicht, Bradley N Jack, Magnus Johannesson, Rhiannon Jones, Evgenii Kalenkovich, Laura Kaltwasser, Hamid Karimi-Rouzbahani, Andreas Keil, Peter König, Layla Kouara, Louisa Kulke, Cecile D Ladouceur, Nicolas Langer, Heinrich R Liesefeld, David Luque, Annmarie MacNamara, Liad Mudrik, Muthuraman Muthuraman, Lauren B Neal, Gustav Nilsonne, Guiomar Niso, Sebastian Ocklenburg, Robert Oostenveld, Cyril R Pernet, Gilles Pourtois, Manuela Ruzzoli, Sarah M Sass, Alexandre Schaefer, Magdalena Senderecka, Joel S Snyder, Christian K Tamnes, Emmanuelle Tognoli, Marieke K van Vugt, Edelyn Verona, Robin Vloeberghs, Dominik Welke, Jan R Wessel, Ilya Zakharov, and Faisal Mushtaq. #EEGManyLabs: investigating the replicability of influential EEG experiments. Cortex, 144:213–229, April 2021.">Pavlov <em>et al.</em>, 2021</a>]</span> will provide a comprehensive dataset in this regard, as many labs with different equipment try to replicate the same studies.</p>
<p class="sd-card-text">Given the large variations across different vendors for all neuroimaging modalities, which often cannot be overcome, it is crucial to report all data acquisition parameters in a comprehensive and standardized manner to make potential differences in data acquisition across studies and sites transparent (for a discussion of reporting guidelines see <a class="reference internal" href="../06/dist.html#s64"><span class="std std-ref">Section 6.4</span></a>).</p>
</div>
</details><details class="sd-sphinx-override sd-dropdown sd-card sd-mb-3 sd-fade-in">
<summary class="sd-summary-title sd-card-header bg-ch3 font-weight-bold">
<span class="fa fa-bolt"></span> 3.2 Stimulus presentation and behavior<div class="sd-summary-down docutils">
<svg version="1.1" width="1.5em" height="1.5em" class="sd-octicon sd-octicon-chevron-down" viewBox="0 0 24 24" aria-hidden="true"><path fill-rule="evenodd" d="M5.22 8.72a.75.75 0 000 1.06l6.25 6.25a.75.75 0 001.06 0l6.25-6.25a.75.75 0 00-1.06-1.06L12 14.44 6.28 8.72a.75.75 0 00-1.06 0z"></path></svg></div>
<div class="sd-summary-up docutils">
<svg version="1.1" width="1.5em" height="1.5em" class="sd-octicon sd-octicon-chevron-up" viewBox="0 0 24 24" aria-hidden="true"><path fill-rule="evenodd" d="M18.78 15.28a.75.75 0 000-1.06l-6.25-6.25a.75.75 0 00-1.06 0l-6.25 6.25a.75.75 0 101.06 1.06L12 9.56l5.72 5.72a.75.75 0 001.06 0z"></path></svg></div>
</summary><div class="sd-summary-content sd-card-body docutils">
<p class="sd-card-text" id="s32">Several actively maintained programs for stimulus presentation and response logging are available. Open source software includes PsychoPy <span id="id30">[<a class="reference internal" href="#id153" title="Jonathan Peirce, Jeremy R Gray, Sol Simpson, Michael MacAskill, Richard Höchenberger, Hiroyuki Sogo, Erik Kastman, and Jonas Kristoffer Lindeløv. PsychoPy2: experiments in behavior made easy. Behavior Research Methods, 51(1):195–203, February 2019.">Peirce <em>et al.</em>, 2019</a>]</span> in Python and Psychtoolbox <span id="id31">[<a class="reference internal" href="#id284" title="David H Brainard. The psychophysics toolbox. Spatial Vision, 10(4):433–436, 1997.">Brainard, 1997</a>, <a class="reference internal" href="#id92" title="M Kleiner, D Brainard, and D Pelli. What's new in psychtoolbox-3? Perception, 2007.">Kleiner <em>et al.</em>, 2007</a>, <a class="reference internal" href="#id277" title="D G Pelli. The VideoToolbox software for visual psychophysics: transforming numbers into movies. Spatial Vision, 10(4):437–442, 1997.">Pelli, 1997</a>]</span> in MATLAB. Both have many users, making it possible to get assistance and perhaps find an already-implemented task protocol (e.g., on Pavlovia for Psychopy). Modality specific resources also exist, for instance the ERP CORE (Compendium of Open Resources and Experiments; Kappenman et al. <span id="id32">Kappenman <em>et al.</em> [<a class="reference internal" href="#id170" title="Emily S Kappenman, Jaclyn L Farrens, Wendy Zhang, Andrew X Stewart, and Steven J Luck. ERP CORE: an open resource for human event-related potential research. Neuroimage, 225:117465, January 2021.">2021</a>]</span> openly provides optimized paradigms for several widely used ERP components, along with scripts, data processing pipelines, and sample data.</p>
<p class="sd-card-text">Using open stimuli and presentation software generally increases the likelihood that other researchers can perform replications, because the stimuli and software will be accessible to them. Although desirable, it is not always possible to use fully open stimuli, particularly in the case of commercial movies, audio plays, and image databases. The license of stimuli one wishes to use should always be checked, as should the license one chooses to attach to a dataset when sharing. Stimuli, presentation scripts, behavioral tests and related material should be shared whenever possible (see <span id="id33">[<a class="reference internal" href="#id190" title="Elizabeth DuPre, Michael Hanke, and Jean-Baptiste Poline. Nature abhors a paywall: how open science can realize the potential of naturalistic stimuli. 2019.">DuPre <em>et al.</em>, 2019</a>]</span> for a list of datasets sharing naturalistic stimuli and <a class="reference internal" href="../06/dist.html"><span class="doc std std-doc">Section 6</span></a>). To facilitate stimuli feature analysis and exact reproducibility of the experimental paradigms, such projects as ReproNim’s ReproStim <span id="id34">[<a class="reference internal" href="#id114" title="Andy Connolly and Yaroslav Halchenko. ReproNim/reprostim:. March 2022.">Connolly and Halchenko, 2022</a>]</span> could automate recording and archival of the delivered to audio-video stimulation. When specific stimuli or material can not be released, they should be described as unambiguously as possible and, if possible, providing the source, such as identification number (e.g., a GTIN), and scripts to (re)produce used stimuli from the commercial media.</p>
</div>
</details><details class="sd-sphinx-override sd-dropdown sd-card sd-mb-3">
<summary class="sd-summary-title sd-card-header">
References on this page<div class="sd-summary-down docutils">
<svg version="1.1" width="1.5em" height="1.5em" class="sd-octicon sd-octicon-chevron-down" viewBox="0 0 24 24" aria-hidden="true"><path fill-rule="evenodd" d="M5.22 8.72a.75.75 0 000 1.06l6.25 6.25a.75.75 0 001.06 0l6.25-6.25a.75.75 0 00-1.06-1.06L12 14.44 6.28 8.72a.75.75 0 00-1.06 0z"></path></svg></div>
<div class="sd-summary-up docutils">
<svg version="1.1" width="1.5em" height="1.5em" class="sd-octicon sd-octicon-chevron-up" viewBox="0 0 24 24" aria-hidden="true"><path fill-rule="evenodd" d="M18.78 15.28a.75.75 0 000-1.06l-6.25-6.25a.75.75 0 00-1.06 0l-6.25 6.25a.75.75 0 101.06 1.06L12 9.56l5.72 5.72a.75.75 0 001.06 0z"></path></svg></div>
</summary><div class="sd-summary-content sd-card-body docutils">
<div class="docutils container" id="id35">
<dl class="citation">
<dt class="label" id="id284"><span class="brackets"><a class="fn-backref" href="#id31">C1</a></span></dt>
<dd><p class="sd-card-text">David H Brainard. The psychophysics toolbox. <em>Spatial Vision</em>, 10(4):433–436, 1997.</p>
</dd>
<dt class="label" id="id131"><span class="brackets"><a class="fn-backref" href="#id7">C2</a></span></dt>
<dd><p class="sd-card-text">Felix A Breuer, Martin Blaimer, Robin M Heidemann, Matthias F Mueller, Mark A Griswold, and Peter M Jakob. Controlled aliasing in parallel imaging results in higher acceleration (CAIPIRINHA) for multi-slice imaging. <em>Magnetic Resonance in Medicine</em>, 53(3):684–691, March 2005.</p>
</dd>
<dt class="label" id="id114"><span class="brackets"><a class="fn-backref" href="#id34">C3</a></span></dt>
<dd><p class="sd-card-text">Andy Connolly and Yaroslav Halchenko. ReproNim/reprostim:. March 2022.</p>
</dd>
<dt class="label" id="id70"><span class="brackets"><a class="fn-backref" href="#id12">C4</a></span></dt>
<dd><p class="sd-card-text">Cristoffer Cordes, Simon Konstandin, David Porter, and Matthias Günther. Portable and platform-independent MR pulse sequence programs. <em>Magnetic Resonance in Medicine</em>, 83(4):1277–1290, April 2020.</p>
</dd>
<dt class="label" id="id271"><span class="brackets"><a class="fn-backref" href="#id22">C5</a></span></dt>
<dd><p class="sd-card-text">Paolo Di Tommaso, Maria Chatzou, Evan W Floden, Pablo Prieto Barja, Emilio Palumbo, and Cedric Notredame. Nextflow enables reproducible computational workflows. <em>Nature Biotechnology</em>, 35(4):316–319, April 2017.</p>
</dd>
<dt class="label" id="id190"><span class="brackets"><a class="fn-backref" href="#id33">C6</a></span></dt>
<dd><p class="sd-card-text">Elizabeth DuPre, Michael Hanke, and Jean-Baptiste Poline. Nature abhors a paywall: how open science can realize the potential of naturalistic stimuli. 2019.</p>
</dd>
<dt class="label" id="id263"><span class="brackets"><a class="fn-backref" href="#id28">C7</a></span></dt>
<dd><p class="sd-card-text">Alexandre Gramfort, Martin Luessi, Eric Larson, Denis A Engemann, Daniel Strohmeier, Christian Brodbeck, Lauri Parkkonen, and Matti S Hämäläinen. MNE software for processing MEG and EEG data. <em>Neuroimage</em>, 86:446–460, February 2014.</p>
</dd>
<dt class="label" id="id125"><span class="brackets"><a class="fn-backref" href="#id7">C8</a></span></dt>
<dd><p class="sd-card-text">Mark A Griswold, Peter M Jakob, Robin M Heidemann, Mathias Nittka, Vladimir Jellus, Jianmin Wang, Berthold Kiefer, and Axel Haase. Generalized autocalibrating partially parallel acquisitions (GRAPPA). <em>Magnetic Resonance in Medicine</em>, 47(6):1202–1210, 2002.</p>
</dd>
<dt class="label" id="id115"><span class="brackets"><a class="fn-backref" href="#id18">C9</a></span></dt>
<dd><p class="sd-card-text">Michael Schacht Hansen and Thomas Sangild Sørensen. Gadgetron: an open source framework for medical image reconstruction. <em>Magnetic Resonance in Medicine</em>, 69(6):1768–1776, June 2013.</p>
</dd>
<dt class="label" id="id89"><span class="brackets">C10</span><span class="fn-backref">(<a href="#id16">1</a>,<a href="#id21">2</a>)</span></dt>
<dd><p class="sd-card-text">Souheil J Inati, Joseph D Naegele, Nicholas R Zwart, Vinai Roopchansingh, Martin J Lizak, David C Hansen, Chia-Ying Liu, David Atkinson, Peter Kellman, Sebastian Kozerke, Hui Xue, Adrienne E Campbell-Washburn, Thomas S Sørensen, and Michael S Hansen. ISMRM raw data format: a proposed standard for MRI raw datasets. <em>Magnetic Resonance in Medicine</em>, 77(1):411–421, January 2017.</p>
</dd>
<dt class="label" id="id241"><span class="brackets"><a class="fn-backref" href="#id9">C11</a></span></dt>
<dd><p class="sd-card-text">V Jellús and S A R Kannengiesser. Adaptive coil combination using a body coil scan as phase reference. <em>Joint Annual Meeting ISMRM-ESMRMB</em>, pages 4406, 2014.</p>
</dd>
<dt class="label" id="id128"><span class="brackets"><a class="fn-backref" href="#id14">C12</a></span></dt>
<dd><p class="sd-card-text">Thies H Jochimsen and Michael von Mengershausen. ODIN: object-oriented development interface for NMR. <em>Journal of Magnetic Resonance</em>, 170(1):67–78, 2004.</p>
</dd>
<dt class="label" id="id170"><span class="brackets"><a class="fn-backref" href="#id32">C13</a></span></dt>
<dd><p class="sd-card-text">Emily S Kappenman, Jaclyn L Farrens, Wendy Zhang, Andrew X Stewart, and Steven J Luck. ERP CORE: an open resource for human event-related potential research. <em>Neuroimage</em>, 225:117465, January 2021.</p>
</dd>
<dt class="label" id="id204"><span class="brackets"><a class="fn-backref" href="#id21">C14</a></span></dt>
<dd><p class="sd-card-text">Agah Karakuzu, Stefan Appelhoff, Tibor Auer, Mathieu Boudreau, Franklin Feingold, Ali R Khan, Alberto Lazari, Christopher Markiewicz, Martjin j Mulder, Christophe Phillips, Taylor Salo, Nikola Stikov, Kirstie Whitaker, and Gilles Hollander. qMRI-BIDS: an extension to the brain imaging data structure for quantitative magnetic resonance imaging data. <em>medRxiv</em>, pages 2021.10.22.21265382, October 2021.</p>
</dd>
<dt class="label" id="id38"><span class="brackets"><a class="fn-backref" href="#id23">C15</a></span></dt>
<dd><p class="sd-card-text">Agah Karakuzu, Labonny Biswas, Julien Cohen‐Adad, and Nikola Stikov. Vendor‐neutral sequences and fully transparent workflows improve inter‐vendor reproducibility of quantitative mri. <em>Magnetic Resonance in Medicine</em>, 88(3):1212–1228, 2022.</p>
</dd>
<dt class="label" id="id93"><span class="brackets"><a class="fn-backref" href="#id23">C16</a></span></dt>
<dd><p class="sd-card-text">Agah Karakuzu, Mathieu Boudreau, Tanguy Duval, Tommy Boshkovski, Ilana Leppert, Jean-François Cabana, Ian Gagnon, Pascale Beliveau, G Pike, Julien Cohen-Adad, and Nikola Stikov. qMRLab: quantitative MRI analysis, under one umbrella. <em>Journal of Open Source Software</em>, 5(53):2343, September 2020.</p>
</dd>
<dt class="label" id="id92"><span class="brackets"><a class="fn-backref" href="#id31">C17</a></span></dt>
<dd><p class="sd-card-text">M Kleiner, D Brainard, and D Pelli. What's new in psychtoolbox-3? <em>Perception</em>, 2007.</p>
</dd>
<dt class="label" id="id266"><span class="brackets"><a class="fn-backref" href="#id20">C18</a></span></dt>
<dd><p class="sd-card-text">Tobias Knopp and Mirco Grosser. MRIReco.jl: an MRI reconstruction framework written in julia. <em>Magnetic Resonance in Medicine</em>, 86(3):1633–1646, September 2021.</p>
</dd>
<dt class="label" id="id73"><span class="brackets"><a class="fn-backref" href="#id10">C19</a></span></dt>
<dd><p class="sd-card-text">Kelvin J Layton, Stefan Kroboth, Feng Jia, Sebastian Littin, Huijun Yu, Jochen Leupold, Jon-Fredrik Nielsen, Tony Stöcker, and Maxim Zaitsev. Pulseq: a rapid and hardware-independent pulse sequence prototyping framework. <em>Magnetic Resonance in Medicine</em>, 77(4):1544–1552, April 2017.</p>
</dd>
<dt class="label" id="id198"><span class="brackets"><a class="fn-backref" href="#id5">C20</a></span></dt>
<dd><p class="sd-card-text">Yoojin Lee, Martina F Callaghan, Julio Acosta-Cabronero, Antoine Lutti, and Zoltan Nagy. Establishing intra- and inter-vendor reproducibility of T relaxation time measurements with 3T MRI. <em>Magnetic Resonance in Medicine</em>, 81(1):454–465, January 2019.</p>
</dd>
<dt class="label" id="id50"><span class="brackets"><a class="fn-backref" href="#id6">C21</a></span></dt>
<dd><p class="sd-card-text">M Lustig, D L Donoho, J M Santos, and J M Pauly. Compressed sensing MRI. <em>IEEE Signal Processing Magazine</em>, 25(2):72–82, March 2008.</p>
</dd>
<dt class="label" id="id121"><span class="brackets"><a class="fn-backref" href="#id15">C22</a></span></dt>
<dd><p class="sd-card-text">Jeremy F Magland, Cheng Li, Michael C Langham, and Felix W Wehrli. Pulse sequence programming in a dynamic visual environment: SequenceTree. <em>Magnetic Resonance in Medicine</em>, 75(1):257–265, January 2016.</p>
</dd>
<dt class="label" id="id178"><span class="brackets"><a class="fn-backref" href="#id17">C23</a></span></dt>
<dd><p class="sd-card-text">Oliver Maier, Steven Hubert Baete, Alexander Fyrdahl, Kerstin Hammernik, Seb Harrevelt, Lars Kasper, Agah Karakuzu, Michael Loecher, Franz Patzig, Ye Tian, Ke Wang, Daniel Gallichan, Martin Uecker, and Florian Knoll. CG-SENSE revisited: results from the first ISMRM reproducibility challenge. <em>Magnetic Resonance in Medicine</em>, 85(4):1821–1839, April 2021.</p>
</dd>
<dt class="label" id="id209"><span class="brackets"><a class="fn-backref" href="#id13">C24</a></span></dt>
<dd><p class="sd-card-text">Jon-Fredrik Nielsen and Douglas C Noll. TOPPE: a framework for rapid prototyping of MR pulse sequences. <em>Magnetic Resonance in Medicine</em>, 79(6):3128–3134, June 2018.</p>
</dd>
<dt class="label" id="id43"><span class="brackets"><a class="fn-backref" href="#id26">C25</a></span></dt>
<dd><p class="sd-card-text">Martin Nørgaard, Melanie Ganz, Claus Svarer, Ling Feng, Masanori Ichise, Rupert Lanzenberger, Mark Lubberink, Ramin V Parsey, Marios Politis, Eugenii A Rabiner, Mark Slifstein, Vesna Sossi, Tetsuya Suhara, Peter S Talbot, Federico Turkheimer, Stephen C Strother, and Gitte M Knudsen. Cerebral serotonin transporter measurements with [11C]DASB: a review on acquisition and preprocessing across 21 PET centres. <em>Journal of Cerebral Blood Flow &amp; Metabolism</em>, 39(2):210–222, 2019.</p>
</dd>
<dt class="label" id="id282"><span class="brackets"><a class="fn-backref" href="#id29">C26</a></span></dt>
<dd><p class="sd-card-text">Yuri G Pavlov, Nika Adamian, Stefan Appelhoff, Mahnaz Arvaneh, Christopher S Y Benwell, Christian Beste, Amy R Bland, Daniel E Bradford, Florian Bublatzky, Niko A Busch, Peter E Clayson, Damian Cruse, Artur Czeszumski, Anna Dreber, Guillaume Dumas, Benedikt Ehinger, Giorgio Ganis, Xun He, José A Hinojosa, Christoph Huber-Huber, Michael Inzlicht, Bradley N Jack, Magnus Johannesson, Rhiannon Jones, Evgenii Kalenkovich, Laura Kaltwasser, Hamid Karimi-Rouzbahani, Andreas Keil, Peter König, Layla Kouara, Louisa Kulke, Cecile D Ladouceur, Nicolas Langer, Heinrich R Liesefeld, David Luque, Annmarie MacNamara, Liad Mudrik, Muthuraman Muthuraman, Lauren B Neal, Gustav Nilsonne, Guiomar Niso, Sebastian Ocklenburg, Robert Oostenveld, Cyril R Pernet, Gilles Pourtois, Manuela Ruzzoli, Sarah M Sass, Alexandre Schaefer, Magdalena Senderecka, Joel S Snyder, Christian K Tamnes, Emmanuelle Tognoli, Marieke K van Vugt, Edelyn Verona, Robin Vloeberghs, Dominik Welke, Jan R Wessel, Ilya Zakharov, and Faisal Mushtaq. #EEGManyLabs: investigating the replicability of influential EEG experiments. <em>Cortex</em>, 144:213–229, April 2021.</p>
</dd>
<dt class="label" id="id153"><span class="brackets"><a class="fn-backref" href="#id30">C27</a></span></dt>
<dd><p class="sd-card-text">Jonathan Peirce, Jeremy R Gray, Sol Simpson, Michael MacAskill, Richard Höchenberger, Hiroyuki Sogo, Erik Kastman, and Jonas Kristoffer Lindeløv. PsychoPy2: experiments in behavior made easy. <em>Behavior Research Methods</em>, 51(1):195–203, February 2019.</p>
</dd>
<dt class="label" id="id277"><span class="brackets"><a class="fn-backref" href="#id31">C28</a></span></dt>
<dd><p class="sd-card-text">D G Pelli. The VideoToolbox software for visual psychophysics: transforming numbers into movies. <em>Spatial Vision</em>, 10(4):437–442, 1997.</p>
</dd>
<dt class="label" id="id85"><span class="brackets"><a class="fn-backref" href="#id11">C29</a></span></dt>
<dd><p class="sd-card-text">Keerthi Ravi, Sairam Geethanath, and John Vaughan. PyPulseq: a python package for MRI pulse sequence design. <em>Journal of Open Source Software</em>, 4(42):1725, October 2019.</p>
</dd>
<dt class="label" id="id251"><span class="brackets"><a class="fn-backref" href="#id5">C30</a></span></dt>
<dd><p class="sd-card-text">Makoto Sasaki, Kei Yamada, Yoshiyuki Watanabe, Mieko Matsui, Masahiro Ida, Shunrou Fujiwara, Eri Shibata, and Acute Stroke Imaging Standardization Group-Japan (ASIST-Japan) Investigators. Variability in absolute apparent diffusion coefficient values across different platforms may be substantial: a multivendor, multi-institutional comparison study. <em>Radiology</em>, 249(2):624–630, November 2008.</p>
</dd>
<dt class="label" id="id189"><span class="brackets"><a class="fn-backref" href="#id8">C31</a></span></dt>
<dd><p class="sd-card-text">Tina Schmitt and Jochem W Rieger. Recommendations of choice of head coil and prescan normalize filter depend on region of interest and task. <em>Frontiers in Neuroscience</em>, 2021.</p>
</dd>
<dt class="label" id="id62"><span class="brackets"><a class="fn-backref" href="#id3">C32</a></span></dt>
<dd><p class="sd-card-text">Stephen M Smith, Christian F Beckmann, Jesper Andersson, Edward J Auerbach, Janine Bijsterbosch, Gwenaëlle Douaud, Eugene Duff, David A Feinberg, Ludovica Griffanti, Michael P Harms, Michael Kelly, Timothy Laumann, Karla L Miller, Steen Moeller, Steve Petersen, Jonathan Power, Gholamreza Salimi-Khorshidi, Abraham Z Snyder, An T Vu, Mark W Woolrich, Junqian Xu, Essa Yacoub, Kamil Uğurbil, David C Van Essen, Matthew F Glasser, and WU-Minn HCP Consortium. Resting-state fMRI in the human connectome project. <em>Neuroimage</em>, 80:144–168, October 2013.</p>
</dd>
<dt class="label" id="id232"><span class="brackets"><a class="fn-backref" href="#id25">C33</a></span></dt>
<dd><p class="sd-card-text">Nikola Stikov, Joshua D Trzasko, and Matt A Bernstein. Reproducibility and the future of MRI research. <em>Magnetic Resonance in Medicine</em>, 82(6):1981–1983, December 2019.</p>
</dd>
<dt class="label" id="id246"><span class="brackets"><a class="fn-backref" href="#id24">C34</a></span></dt>
<dd><p class="sd-card-text">Gehua Tong, Andreia S Gaspar, Enlin Qian, Keerthi Sravan Ravi, John Thomas Vaughan, Jr, Rita G Nunes, and Sairam Geethanath. A framework for validating open-source pulse sequences. <em>Magnetic Resonance Imaging</em>, 87:7–18, November 2021.</p>
</dd>
<dt class="label" id="id52"><span class="brackets"><a class="fn-backref" href="#id19">C35</a></span></dt>
<dd><p class="sd-card-text">Martin Uecker, Frank Ong, Jonathan I Tamir, Dara Bahri, Patrick Virtue, Joseph Y Cheng, Tao Zhang, and Michael Lustig. Berkeley advanced reconstruction toolbox (BART). <em>Proc. of. the International Society for Magnetic Resonance in Medicine (ISMRM)</em>, October 2015.</p>
</dd>
<dt class="label" id="id90"><span class="brackets"><a class="fn-backref" href="#id4">C36</a></span></dt>
<dd><p class="sd-card-text">Kamil Uğurbil, Junqian Xu, Edward J Auerbach, Steen Moeller, An T Vu, Julio M Duarte-Carvajalino, Christophe Lenglet, Xiaoping Wu, Sebastian Schmitter, Pierre Francois Van de Moortele, John Strupp, Guillermo Sapiro, Federico De Martino, Dingxin Wang, Noam Harel, Michael Garwood, Liyong Chen, David A Feinberg, Stephen M Smith, Karla L Miller, Stamatios N Sotiropoulos, Saad Jbabdi, Jesper L R Andersson, Timothy E J Behrens, Matthew F Glasser, David C Van Essen, Essa Yacoub, and WU-Minn HCP Consortium. Pushing spatial and temporal resolution for functional and diffusion MRI in the human connectome project. <em>Neuroimage</em>, 80:80–104, October 2013.</p>
</dd>
<dt class="label" id="id80"><span class="brackets"><a class="fn-backref" href="#id27">C37</a></span></dt>
<dd><p class="sd-card-text">V-V Wettenhovi, M Vauhkonen, and V Kolehmainen. OMEGA: open-source emission tomography software. <em>Physics in Medicine and Biology</em>, 2021.</p>
</dd>
<dt class="label" id="id281"><span class="brackets"><a class="fn-backref" href="#id1">C38</a></span></dt>
<dd><p class="sd-card-text">Lukas Winter, H Haopeng, Antonia Barghoorn, Werner Hoffmann, Stefan Hetzer, Simone Winkler, and Others. Open source imaging initiative. <em>Proc. of. the International Society for Magnetic Resonance in Medicine (ISMRM)</em>, 2016.</p>
</dd>
</dl>
</div>
</div>
</details><hr class="footnotes docutils" />
<dl class="footnote brackets">
<dt class="label" id="footnote2"><span class="brackets"><a class="fn-backref" href="#id2">1</a></span></dt>
<dd><p>Sources: Icons from the Noun Project: Brain by parkjisun; Computer Screen by Icon Solid (adapted with a star); Logos: used with permission by the copyright holders.</p>
</dd>
</dl>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./03"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
            </main>
            <footer class="footer-article noprint">
                
    <!-- Previous / next buttons -->
<div class='prev-next-area'>
    <a class='left-prev' id="prev-link" href="../02/ipe.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title">Study inception, planning, and ethics</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="../04/data.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Research data management</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
            </footer>
        </div>
    </div>
    <div class="footer-content row">
        <footer class="col footer"><p>
  
    By Guiomar Niso, Rotem Botvinik-Nezer, Stefan Appelhoff, Alejandro De La Vega, Oscar Esteban, Joset A. Etzel, Karolina Finc, Melanie Ganz, Rémi Gau, Yaroslav O. Halchenko, Peer Herholz, Agah Karakuzu, David B. Keator, Christopher J. Markiewicz, Camille Maumet, Cyril R. Pernet, Franco Pestilli, Nazek Queder, Tina Schmitt, Weronika Sójka, Adina S. Wagner, Kirstie J. Whitaker, Jochem W. Rieger<br/>
  
      &copy; Copyright 2022.<br/>
    <div class="extra_footer">
      <img href="http://creativecommons.org/publicdomain/zero/1.0/" src="https://licensebuttons.net/l/zero/1.0/80x15.png" alt="CC0 licence">
    </div>
</p>
        </footer>
    </div>
    
</div>


      </div>
    </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf"></script>


  </body>
</html>